{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perceived-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "from pylab import *\n",
    "import os\n",
    "import pandas as pd\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "# import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-contrast",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fuzzy-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-573.379150</td>\n",
       "      <td>34.064041</td>\n",
       "      <td>-33.337578</td>\n",
       "      <td>3.489916</td>\n",
       "      <td>-13.482152</td>\n",
       "      <td>-6.327230</td>\n",
       "      <td>-17.734171</td>\n",
       "      <td>-15.280941</td>\n",
       "      <td>-8.379515</td>\n",
       "      <td>-0.323866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323118</td>\n",
       "      <td>-0.797864</td>\n",
       "      <td>-0.332338</td>\n",
       "      <td>0.177740</td>\n",
       "      <td>0.204333</td>\n",
       "      <td>-0.211895</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>-0.274973</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-545.244568</td>\n",
       "      <td>38.073475</td>\n",
       "      <td>-8.023163</td>\n",
       "      <td>7.236882</td>\n",
       "      <td>-13.688817</td>\n",
       "      <td>-2.157916</td>\n",
       "      <td>-12.315373</td>\n",
       "      <td>-7.948586</td>\n",
       "      <td>-14.858138</td>\n",
       "      <td>1.719064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.029629</td>\n",
       "      <td>-0.052548</td>\n",
       "      <td>-0.059842</td>\n",
       "      <td>-0.084479</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>-0.165808</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-690.535461</td>\n",
       "      <td>43.141396</td>\n",
       "      <td>-9.854416</td>\n",
       "      <td>10.819540</td>\n",
       "      <td>-14.295117</td>\n",
       "      <td>-2.288000</td>\n",
       "      <td>-10.151420</td>\n",
       "      <td>-4.941710</td>\n",
       "      <td>-6.615477</td>\n",
       "      <td>-2.972474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057103</td>\n",
       "      <td>-0.174446</td>\n",
       "      <td>-0.116118</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>0.191797</td>\n",
       "      <td>-0.322106</td>\n",
       "      <td>-0.287355</td>\n",
       "      <td>0.132173</td>\n",
       "      <td>8</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-553.611633</td>\n",
       "      <td>41.233486</td>\n",
       "      <td>-9.912664</td>\n",
       "      <td>8.587062</td>\n",
       "      <td>-5.737630</td>\n",
       "      <td>-5.831647</td>\n",
       "      <td>-17.839375</td>\n",
       "      <td>-11.084945</td>\n",
       "      <td>-11.369494</td>\n",
       "      <td>3.470583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.068387</td>\n",
       "      <td>0.201094</td>\n",
       "      <td>-0.062219</td>\n",
       "      <td>-0.291406</td>\n",
       "      <td>-0.284542</td>\n",
       "      <td>0.070689</td>\n",
       "      <td>0.088308</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-576.153442</td>\n",
       "      <td>49.947994</td>\n",
       "      <td>-13.857949</td>\n",
       "      <td>8.248825</td>\n",
       "      <td>-12.159565</td>\n",
       "      <td>0.193612</td>\n",
       "      <td>-8.719680</td>\n",
       "      <td>-7.731155</td>\n",
       "      <td>-8.692744</td>\n",
       "      <td>0.833810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276208</td>\n",
       "      <td>-0.723615</td>\n",
       "      <td>0.074101</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.288559</td>\n",
       "      <td>-0.022368</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.346106</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4         5  \\\n",
       "0 -573.379150  34.064041 -33.337578   3.489916 -13.482152 -6.327230   \n",
       "1 -545.244568  38.073475  -8.023163   7.236882 -13.688817 -2.157916   \n",
       "2 -690.535461  43.141396  -9.854416  10.819540 -14.295117 -2.288000   \n",
       "3 -553.611633  41.233486  -9.912664   8.587062  -5.737630 -5.831647   \n",
       "4 -576.153442  49.947994 -13.857949   8.248825 -12.159565  0.193612   \n",
       "\n",
       "           6          7          8         9  ...       120       121  \\\n",
       "0 -17.734171 -15.280941  -8.379515 -0.323866  ... -0.323118 -0.797864   \n",
       "1 -12.315373  -7.948586 -14.858138  1.719064  ...  0.066087  0.029629   \n",
       "2 -10.151420  -4.941710  -6.615477 -2.972474  ...  0.057103 -0.174446   \n",
       "3 -17.839375 -11.084945 -11.369494  3.470583  ...  0.015315  0.068387   \n",
       "4  -8.719680  -7.731155  -8.692744  0.833810  ... -0.276208 -0.723615   \n",
       "\n",
       "        122       123       124       125       126       127  label  emotions  \n",
       "0 -0.332338  0.177740  0.204333 -0.211895  0.080943 -0.274973      6   fearful  \n",
       "1 -0.052548 -0.059842 -0.084479  0.181888  0.202147 -0.165808      5     angry  \n",
       "2 -0.116118  0.133232  0.191797 -0.322106 -0.287355  0.132173      8  surprise  \n",
       "3  0.201094 -0.062219 -0.291406 -0.284542  0.070689  0.088308      6   fearful  \n",
       "4  0.074101  0.027505  0.288559 -0.022368  0.053056  0.346106      5     angry  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/voice_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proprietary-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-573.379150</td>\n",
       "      <td>34.064041</td>\n",
       "      <td>-33.337578</td>\n",
       "      <td>3.489916</td>\n",
       "      <td>-13.482152</td>\n",
       "      <td>-6.327230</td>\n",
       "      <td>-17.734171</td>\n",
       "      <td>-15.280941</td>\n",
       "      <td>-8.379515</td>\n",
       "      <td>-0.323866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428459</td>\n",
       "      <td>-0.323118</td>\n",
       "      <td>-0.797864</td>\n",
       "      <td>-0.332338</td>\n",
       "      <td>0.177740</td>\n",
       "      <td>0.204333</td>\n",
       "      <td>-0.211895</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>-0.274973</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-545.244568</td>\n",
       "      <td>38.073475</td>\n",
       "      <td>-8.023163</td>\n",
       "      <td>7.236882</td>\n",
       "      <td>-13.688817</td>\n",
       "      <td>-2.157916</td>\n",
       "      <td>-12.315373</td>\n",
       "      <td>-7.948586</td>\n",
       "      <td>-14.858138</td>\n",
       "      <td>1.719064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031505</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.029629</td>\n",
       "      <td>-0.052548</td>\n",
       "      <td>-0.059842</td>\n",
       "      <td>-0.084479</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>-0.165808</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-690.535461</td>\n",
       "      <td>43.141396</td>\n",
       "      <td>-9.854416</td>\n",
       "      <td>10.819540</td>\n",
       "      <td>-14.295117</td>\n",
       "      <td>-2.288000</td>\n",
       "      <td>-10.151420</td>\n",
       "      <td>-4.941710</td>\n",
       "      <td>-6.615477</td>\n",
       "      <td>-2.972474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236663</td>\n",
       "      <td>0.057103</td>\n",
       "      <td>-0.174446</td>\n",
       "      <td>-0.116118</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>0.191797</td>\n",
       "      <td>-0.322106</td>\n",
       "      <td>-0.287355</td>\n",
       "      <td>0.132173</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-553.611633</td>\n",
       "      <td>41.233486</td>\n",
       "      <td>-9.912664</td>\n",
       "      <td>8.587062</td>\n",
       "      <td>-5.737630</td>\n",
       "      <td>-5.831647</td>\n",
       "      <td>-17.839375</td>\n",
       "      <td>-11.084945</td>\n",
       "      <td>-11.369494</td>\n",
       "      <td>3.470583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129597</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.068387</td>\n",
       "      <td>0.201094</td>\n",
       "      <td>-0.062219</td>\n",
       "      <td>-0.291406</td>\n",
       "      <td>-0.284542</td>\n",
       "      <td>0.070689</td>\n",
       "      <td>0.088308</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-576.153442</td>\n",
       "      <td>49.947994</td>\n",
       "      <td>-13.857949</td>\n",
       "      <td>8.248825</td>\n",
       "      <td>-12.159565</td>\n",
       "      <td>0.193612</td>\n",
       "      <td>-8.719680</td>\n",
       "      <td>-7.731155</td>\n",
       "      <td>-8.692744</td>\n",
       "      <td>0.833810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525122</td>\n",
       "      <td>-0.276208</td>\n",
       "      <td>-0.723615</td>\n",
       "      <td>0.074101</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.288559</td>\n",
       "      <td>-0.022368</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.346106</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4         5  \\\n",
       "0 -573.379150  34.064041 -33.337578   3.489916 -13.482152 -6.327230   \n",
       "1 -545.244568  38.073475  -8.023163   7.236882 -13.688817 -2.157916   \n",
       "2 -690.535461  43.141396  -9.854416  10.819540 -14.295117 -2.288000   \n",
       "3 -553.611633  41.233486  -9.912664   8.587062  -5.737630 -5.831647   \n",
       "4 -576.153442  49.947994 -13.857949   8.248825 -12.159565  0.193612   \n",
       "\n",
       "           6          7          8         9  ...       119       120  \\\n",
       "0 -17.734171 -15.280941  -8.379515 -0.323866  ...  0.428459 -0.323118   \n",
       "1 -12.315373  -7.948586 -14.858138  1.719064  ... -0.031505  0.066087   \n",
       "2 -10.151420  -4.941710  -6.615477 -2.972474  ...  0.236663  0.057103   \n",
       "3 -17.839375 -11.084945 -11.369494  3.470583  ... -0.129597  0.015315   \n",
       "4  -8.719680  -7.731155  -8.692744  0.833810  ...  0.525122 -0.276208   \n",
       "\n",
       "        121       122       123       124       125       126       127  label  \n",
       "0 -0.797864 -0.332338  0.177740  0.204333 -0.211895  0.080943 -0.274973      6  \n",
       "1  0.029629 -0.052548 -0.059842 -0.084479  0.181888  0.202147 -0.165808      5  \n",
       "2 -0.174446 -0.116118  0.133232  0.191797 -0.322106 -0.287355  0.132173      8  \n",
       "3  0.068387  0.201094 -0.062219 -0.291406 -0.284542  0.070689  0.088308      6  \n",
       "4 -0.723615  0.074101  0.027505  0.288559 -0.022368  0.053056  0.346106      5  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(inplace=True, columns=[\"emotions\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proof-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "willing-taylor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-573.379150</td>\n",
       "      <td>34.064041</td>\n",
       "      <td>-33.337578</td>\n",
       "      <td>3.489916</td>\n",
       "      <td>-13.482152</td>\n",
       "      <td>-6.327230</td>\n",
       "      <td>-17.734171</td>\n",
       "      <td>-15.280941</td>\n",
       "      <td>-8.379515</td>\n",
       "      <td>-0.323866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334692</td>\n",
       "      <td>0.428459</td>\n",
       "      <td>-0.323118</td>\n",
       "      <td>-0.797864</td>\n",
       "      <td>-0.332338</td>\n",
       "      <td>0.177740</td>\n",
       "      <td>0.204333</td>\n",
       "      <td>-0.211895</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>-0.274973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-545.244568</td>\n",
       "      <td>38.073475</td>\n",
       "      <td>-8.023163</td>\n",
       "      <td>7.236882</td>\n",
       "      <td>-13.688817</td>\n",
       "      <td>-2.157916</td>\n",
       "      <td>-12.315373</td>\n",
       "      <td>-7.948586</td>\n",
       "      <td>-14.858138</td>\n",
       "      <td>1.719064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079512</td>\n",
       "      <td>-0.031505</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.029629</td>\n",
       "      <td>-0.052548</td>\n",
       "      <td>-0.059842</td>\n",
       "      <td>-0.084479</td>\n",
       "      <td>0.181888</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>-0.165808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-690.535461</td>\n",
       "      <td>43.141396</td>\n",
       "      <td>-9.854416</td>\n",
       "      <td>10.819540</td>\n",
       "      <td>-14.295117</td>\n",
       "      <td>-2.288000</td>\n",
       "      <td>-10.151420</td>\n",
       "      <td>-4.941710</td>\n",
       "      <td>-6.615477</td>\n",
       "      <td>-2.972474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045710</td>\n",
       "      <td>0.236663</td>\n",
       "      <td>0.057103</td>\n",
       "      <td>-0.174446</td>\n",
       "      <td>-0.116118</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>0.191797</td>\n",
       "      <td>-0.322106</td>\n",
       "      <td>-0.287355</td>\n",
       "      <td>0.132173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-553.611633</td>\n",
       "      <td>41.233486</td>\n",
       "      <td>-9.912664</td>\n",
       "      <td>8.587062</td>\n",
       "      <td>-5.737630</td>\n",
       "      <td>-5.831647</td>\n",
       "      <td>-17.839375</td>\n",
       "      <td>-11.084945</td>\n",
       "      <td>-11.369494</td>\n",
       "      <td>3.470583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175183</td>\n",
       "      <td>-0.129597</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>0.068387</td>\n",
       "      <td>0.201094</td>\n",
       "      <td>-0.062219</td>\n",
       "      <td>-0.291406</td>\n",
       "      <td>-0.284542</td>\n",
       "      <td>0.070689</td>\n",
       "      <td>0.088308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-576.153442</td>\n",
       "      <td>49.947994</td>\n",
       "      <td>-13.857949</td>\n",
       "      <td>8.248825</td>\n",
       "      <td>-12.159565</td>\n",
       "      <td>0.193612</td>\n",
       "      <td>-8.719680</td>\n",
       "      <td>-7.731155</td>\n",
       "      <td>-8.692744</td>\n",
       "      <td>0.833810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403427</td>\n",
       "      <td>0.525122</td>\n",
       "      <td>-0.276208</td>\n",
       "      <td>-0.723615</td>\n",
       "      <td>0.074101</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.288559</td>\n",
       "      <td>-0.022368</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.346106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4         5  \\\n",
       "0 -573.379150  34.064041 -33.337578   3.489916 -13.482152 -6.327230   \n",
       "1 -545.244568  38.073475  -8.023163   7.236882 -13.688817 -2.157916   \n",
       "2 -690.535461  43.141396  -9.854416  10.819540 -14.295117 -2.288000   \n",
       "3 -553.611633  41.233486  -9.912664   8.587062  -5.737630 -5.831647   \n",
       "4 -576.153442  49.947994 -13.857949   8.248825 -12.159565  0.193612   \n",
       "\n",
       "           6          7          8         9  ...       118       119  \\\n",
       "0 -17.734171 -15.280941  -8.379515 -0.323866  ... -0.334692  0.428459   \n",
       "1 -12.315373  -7.948586 -14.858138  1.719064  ... -0.079512 -0.031505   \n",
       "2 -10.151420  -4.941710  -6.615477 -2.972474  ... -0.045710  0.236663   \n",
       "3 -17.839375 -11.084945 -11.369494  3.470583  ... -0.175183 -0.129597   \n",
       "4  -8.719680  -7.731155  -8.692744  0.833810  ... -0.403427  0.525122   \n",
       "\n",
       "        120       121       122       123       124       125       126  \\\n",
       "0 -0.323118 -0.797864 -0.332338  0.177740  0.204333 -0.211895  0.080943   \n",
       "1  0.066087  0.029629 -0.052548 -0.059842 -0.084479  0.181888  0.202147   \n",
       "2  0.057103 -0.174446 -0.116118  0.133232  0.191797 -0.322106 -0.287355   \n",
       "3  0.015315  0.068387  0.201094 -0.062219 -0.291406 -0.284542  0.070689   \n",
       "4 -0.276208 -0.723615  0.074101  0.027505  0.288559 -0.022368  0.053056   \n",
       "\n",
       "        127  \n",
       "0 -0.274973  \n",
       "1 -0.165808  \n",
       "2  0.132173  \n",
       "3  0.088308  \n",
       "4  0.346106  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(\"label\", axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portable-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "silent-drama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1611    5\n",
       "1057    3\n",
       "3033    6\n",
       "1399    5\n",
       "472     3\n",
       "       ..\n",
       "1130    3\n",
       "1294    4\n",
       "860     5\n",
       "3507    5\n",
       "3174    6\n",
       "Name: label, Length: 2664, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spanish-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "X_scaler = load('scaler.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "italic-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moved-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "related-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=256, activation='relu', input_dim=128))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excited-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 101,129\n",
      "Trainable params: 101,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "competitive-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "short-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 - 0s - loss: 0.8509 - accuracy: 0.7012\n",
      "Epoch 2/10\n",
      "84/84 - 0s - loss: 0.4469 - accuracy: 0.8393\n",
      "Epoch 3/10\n",
      "84/84 - 0s - loss: 0.3319 - accuracy: 0.8878\n",
      "Epoch 4/10\n",
      "84/84 - 0s - loss: 0.2367 - accuracy: 0.9230\n",
      "Epoch 5/10\n",
      "84/84 - 0s - loss: 0.1668 - accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "84/84 - 0s - loss: 0.1128 - accuracy: 0.9681\n",
      "Epoch 7/10\n",
      "84/84 - 0s - loss: 0.0709 - accuracy: 0.9854\n",
      "Epoch 8/10\n",
      "84/84 - 0s - loss: 0.0514 - accuracy: 0.9906\n",
      "Epoch 9/10\n",
      "84/84 - 0s - loss: 0.0285 - accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "84/84 - 0s - loss: 0.0139 - accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e929381d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fundamental-poster",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9a95bf92bac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \"\"\"\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, predictions,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
